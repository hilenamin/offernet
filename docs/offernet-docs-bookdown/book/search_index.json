[
["index.html", "Offer Network: concept and implementation Chapter 1 Preface", " Offer Network: concept and implementation Kabir Veitas (kabir@singularitynet.io) 2018-05-11 Chapter 1 Preface "],
["conceptual-framework.html", "Chapter 2 Conceptual framework 2.1 Open problems / features to consider 2.2 Conceptual Architecture 2.3 Performance measure 2.4 Goals and phases of the project 2.5 Practical use cases and models", " Chapter 2 Conceptual framework 2.1 Open problems / features to consider Open problems and features are are conceptual and ‘implementation’ issues that the system has to address in one or another way or at least provide a potential to do that. There is not particular order to the listed items now and they will be updated as the work progresses. 2.1.1 Representation / theory of value In monetary exchange, the value of items is represented in a ‘flat’ and ‘one-dimensional’ way – in terms of money – which abstracts away subjective differences in how heterogenous agents value the same items of exchange. The main idea of Offer Networks is to allow for these subjective values to be [partially] externalized in a distributed marketplace in order to enable peer-to-peer exchanges. This should increase the total generation of value as compared to monetary markets which support consumerist dynamics. Yet the theory of value goes beyond purely Offer Networks concept and implementation. Usually theories of value try to posit some sort of globally accepted measure of value, existence of which alone facilitates the exchange of goods – giving rise for transactional role of money. Yet the notion of global measure of value automatically takes away the subjective values and local aspect of exchange – precisely the things that Offer Network is supposed to bring back. In any case, expression and communication of subjective values will involve some sort of simplification (in terms of map, vector representations or just behavioral preferences) which will need to be experimented with in a simulation model. 2.1.2 Representation / description of items of exchange Whatever will be exchanged in the market will have to be somehow represented and stored in a system for subsequent search and discovery by other agents. This is obvious but not simple, taking into account that every agent may ‘want’ to express its subjective preferences regarding concrete item offered / demanded. Ways to represent items could be: Limited number of hard-coded types. Obviously simplest to implement (and, depending on the angle of simulation, could be practical for the start), yet less realistic for a full fledged Offer Networks system. Natural language descriptions (or at least structured natural language). This seems to be most realistic, but also hardest to implement, as would need some sort of NLP capabilities on behalf of agents. The advantage is that it would allow seamless interaction of humans with the system (see HMI). Vector representations. A sort of a middle ground between natural language and hard coded types; I am currently in favor of this one, since it allows to define a simple similarity measure between items within exchange – allowing also to map them with ‘fuzzy’ or ‘incomplete’ preferences – which is an essential and necessary feature of the system; Map representations. The problem with vector representations is that they will require a sort of global key map for the values in a vector. In a map representation, and agent could explicitly indicate keys and their values. The similarity calculation may become somewhat more complicated in this case. Sparse Distributed Representation (of HTM) (Ahmad and Hawkins 2015). Just an idea so far, but could be interesting to explore. 2.1.3 Similarity measure It should be possible to calculate similarity measures between items traded and their values (which is by the way not the same, taken into account emphasis on subjective values in Offer Networks…). This is where representation of items becomes important. The need of similarity measure also becomes important if taking into account incomplete preferences of agents – they will somehow will need to find items that map to those incomplete preferences. 2.1.4 Matching algorithm and search Given a (potentially huge) set of agents with {demand, offer} pairs, where demands and offers are items represented in a chosen way (see representation of items), an atomic task of an Offer Network at any point of time would be to find the items demanded by some agents which are offered by other agents and swap them so that the value created for agents participating in an exchange increases. For the problematics related to the ‘total value’ see discussion on centralization / decentralization which is not directly related to the matching algorithm / search (except that matching algorithm itself is related to it…;). For the problematics of the very ‘search’ problem in Offer Network, see incomplete preferences / selection for relevance. Possible matching / search algorithms: Proposed in (B. Goertzel 2015a) by ben@singularitynet.io: Reducing the ON Matching problem to Weighted Boolean Optimization / MaxSAT;; Mapping ON Matching problem into OpenCog Atomspace and solving with the Open-WBO/MaxSAT solvers on it; Proposed, formalized and experimented with in (Goertzel 2017) by Zar Goertzel: Maximum Edge-Weight Matching (MAX-WEIGHT) Maximum 2-way Matching (MAX-2) Greedy Shortest Cycle (GSC) Dynamic Shortest Cycle (DYN-SC) Hanging ORpairs (HOR) Proposed in [unpublished] by kabir@singularitynet.io: Aggregation of distributed vertex-based computations on a graph (see Computational Framework for details) 2.1.5 Incomplete preferences and selection for relevance In any close to realistic scenario agents cannot have complete and full preferences about everything what they demand / want (surely not if agents are humans) as well as an item of exchange cannot be represented completely and ‘non-ambiguously’. Furthermore, and more importantly conceptually, incomplete preferences of agents actually allow for communication, interaction, coordination and emergence rather than prevent it. Therefore allowing for incomplete preferences and foreseeing the mechanism of negotiation / individuation of incomplete (or in extreme cases – completely non-existent) preferences of interacting agents into behavioral choices is an essential aspect of a system aspiring for self-organizing dynamics. See The resolution of disparity in (Weinbaum (Weaver) and Veitas 2017) for a conceptual treatment of this aspect. The important implication for Offer Networks is that ‘matching’ of demands and offers or ‘finding’ chains of exchanges among several agents is actually not at all a search problem given the space of possibilities ({offer, demand} pairs) but rather the result of dynamic interaction / negotiation among agents, in which concrete preferences / behaviours (not present before interaction) emerge from incomplete preferences, disparities and partial [in]compatibilities. The former (search) is a special case of the latter (negotiation) and the system architecture should at least attempt / consider the general case / framework before delving into implementation of special cases – which are nonetheless important. The main centralization / decentralization (see later) issue is that in decentralized system there is no universal way to define relevance of items to all participants of the system (provide ‘best’ measures, ‘best’ reputation systems, etc.). Heterogeneous participants / agents will have different preferences and will select different aspects of the same item as important / unimportant to them – so will base decisions on a mechanism called selection for relevance. Consider also, that for any non-trivial agent the enacted preferences depend on the specific situation (e.g. Fido-dog agent built with OpenCog had a parameter ‘pee urgency’ which influenced its decisions…:)) as well as these preferences are incomplete in the first place. The implication is that preferences of agents can be identified and enacted only in the actual interaction of agents in the network and not prior to that. Anything beyond this (e.g. positing a global search mechanism / algorithm which chooses what is best for each agent based on their pre-announced preferences) is a movement towards centralization of a system – which may be needed or even desirable provided that limitations and advantages are wholly considered. 2.1.6 Human-machine interface The vision of Offer Networks as an alternative economy first and foremost is concerned about increasing the welfare of humans and enriching ‘their’ economies (B. Goertzel 2015b, 3). Therefore human participation should be considered in the design of the system, albeit most probably not in early experiments. Leaving aside technical issues of the interface this presents at least two more conceptual issues/challenges: 1) Representing human preferences is tricky. It is obviously related to the representation of value and items of exchange issues as well as incomplete preferences. 2) Humans will not participate in the system that asks them to list more than a few of their preferences (even if they know them for sure which is often not the case) about demands and characteristics of offered items. The SingularityNET-type solution seems to be to populate an Offer Network with AI agents representing preferences of people and having ability to interact with them in order to learn those preferences – and that would be a basis for Human-Machine Interface (see Conceptual architecture further in this document). 2.1.7 Centralization / decentralization We use the following definition of decentralization: a system is decentralized if no agent has an ability to directly access the global state of the system. This does not prevent it to indirectly infer or collect the information about the system that allows to construct a representation of a global state (like Google does with Internet :); Likewise, a centralized system is where a single agent (or agents) have a privileged role to access a global state of the system, collect information about it and provide such ‘global unified view’ to the other agents in the system (almost like Google does with Internet :)); Google’s example fits to both definitions which is the result of ‘rich becomes richer’ network dynamics illustrating that an initially decentralized system (Internet) can become centralized by merely a self-organized process (preferential attachment network dynamics). It also illustrates that in reality there are no strict borders between centralized and decentralized systems – they form a continuum (see here for more. Suppose that a system initially consists of completely homogenous (in terms of knowledge/degree of connectivity and processing capacities) agents which are trying to find best ‘friends’ in the network. If these agents are autonomous, sooner or later some of them will turn out to be more successful so other agents will start finding ‘friends’ through them – they will become Facebooks and Googles of the SingularityNET – this dynamics is general for any self-organizing system of autonomous agents. Note, that without such mechanism, complexification, evolution and learning in and of a system is impossible. On the other hand, when a few agents become so powerful that they start to influence decisions of majority of other agents in the network, the availability of diversity of the network decreases – and that again prevents complexification, evolution and learning. Furthermore, self-organization and search is a resource hungry process, therefore we want some sort of mechanism which propagates successful strategies/knowledge that can be utilized by others. Furthermore #2, the preferred balance between centralization / decentralization (degree distribution in a network if you will) depends on specific challenges and environment that the system is being exposed to. E.g. in stable times it may be globally beneficial to have more centralization and utilize / share a few best patterns of behavior, yet during volatile times it may be instrumental for the overall survival / stability of the system to experiment more (so destroy centralized hierarchies / neglect the highest degree nodes, etc.). Bottom line is that an ideal system capable of evolving and learning should not be centralized or decentralized, but it has to dynamically find a way to combine two modes of operation and fluidly change their balance depending on circumstances. The conceptual problem is that internal ‘rich becomes richer’ dynamics is natural to decentralized systems / networks, yet the dissolution of centralized networks is not – it usually has to come from external sources with a threat to destroy the system… (see processes of integration and disintegration in (Veitas and Weinbaum 2015) for more). This discussion provides a few guiding principles for the architectural design: 1. It has to be flexible enough for implementing, testing and evaluating many different centralization / decentralization mechanisms and behaviors (in terms of Offer Network – matching algorithms, representations and other features mentioned in this section); 2. It has to allow for variety (at least in principle if not from day one) in the system so that to allow agents themselves to have a say about the preferred / best matching algorithm, reputation system, representation, etc. 3. The system has to be able to learn / spread new useful patterns and to forget old or not-useful ones fast. The ideal criteria for a successful system would be its fluidity in adapting (learning new and forgetting old) rather than optimality / efficiency with respect to a static situation (while it could be an aspect to consider too); The goal of the architectural design is to express / operationalize these principles in computational terms and build a simulation environment / framework to experiment with them – which is the topic of computational framework. Note also that from the computational standpoint, centralized algorithms are almost always more measurably efficient than decentralized for a simple (yet fundamental) reason that self-organization and resolution of disparities need additional resources (of time and memory). Finding clear cases, especially lending themselves to computer simulations with efficiency criteria that could give justice to Offer Networks distributed system is far from trivial and requires a rich simulation framework. 2.1.8 Memory / learning: emergence of identities A system that learns has necessary to have a memory in order to be able to remember (and forget) patterns. For a network of agents (including Offer Network and SingularityNET) such memory is a connectivity pattern among them. If a network of collaborating agents find an efficient way to pool their resources / competences and to solve complex type of problems together that cannot be solved individually it represents a new pattern. If this pattern becomes persistent, conceptually it can be viewed as a kind of ‘super-agent’ – so a new emerged identity in the network. For the conceptual treatment of the process see A descriptive model of the individuation of cognition (Weinbaum (Weaver) and Veitas 2017). In computational framework part we try to see if a computational framework able to support this process and still be practically testable / usable can be conceived and implemented. 2.1.9 Storage of value / timed exchanges In the specific case of Offer Networks, memory (apart from persistent connectivity patterns) is the ability to store value by agents (represented in reputation / tokens, etc.) for the usage later in timed exchanges. This is an essential aspect of the system and has to be considered in the early design (if not in early implementations). 2.2 Conceptual Architecture Taken into account all open problems / features to consider the proposed conceptual architecture of Offer Networks is summarized in the picture below. The goal of simulation modelling is to experiment and test more or less isolated aspects of this architecture (following envisaged goals and phases of the project) taking into account the future need for eventual integration of the results into the complete framework. Figure 2.1: Conceptual architecture of OfferNet In this architecture, the Offer Network consists of humans, which are represented by one or more ON-AI agent, which learns the behavior/preferences of the represented human relevant to its role in an Offer Network. An ON-AI agent formulates and owns sets of rules of exchange == conditions of how items (owned by the human) are offered and demanded in the network. Items are represented in a way that allows to calculate their similarity and match most similar items (i.e if an item1 offered by agent1 is sufficiently similar to item2 demanded by agent2 then there is a high probability that it is a match and the exchange can be executed. In case the similarity is not perfect (in real scenarios this will be always the case), the differences and incomplete preferences have to be resolved via negotiation of respective ON-AI agents with or without human intervention if AI agents cannot solve the issue themselves – implying more complex information flows within the network than just passing commands of humans to AI agents and then network. We may also consider that humans that form the ‘outer’ layer of the network form a social network by knowing each other outside the Offer Network. This fact allows for distributed operation of the network without central authority – humans would join the network only via recommendations of friends. This social network could also be a basis for the distributed reputation system where reputation of an agent would depend on the reputation of its friends in Page Rank / Google Guice style. Of course the initial social network would be augmented by a social network between ON-AI agents on the basis of their operation already within Offer Network. The social network structure is important for distributed search of similar items, since (provided that the ‘small-world’ structure) every agent of the network can potentially reach every other agent in the network via small number of links1. The efficiency of the operation of the network depends not only on the ‘smartness’ of ON-AI agents, but also on the structure of the network. The conceptual model does not prevent for introduction of additional ‘governing’, ‘matching’ or ‘similarity search’ agents operating on the same data structure. 1: https://en.wikipedia.org/wiki/Small-world_network 2.3 Performance measure Measuring ‘performance’ of the network of heterogeneous agents each having subjective values and running different processes without resorting to some sort of over-simplistic average (like amount of money or reputation at the end of the simulation) is a tricky issue. Yet we need some kind of ways to distinguish successful simulations from unsuccessful ones. Possibilities are listed below: Proposed, formalized and experimented with in (Goertzel 2017) by Zar Goertzel: (TM): Total number of ORpairs satisfactorily matched. (WT): Average wait time of ORpairs that are matched. (AMS): Average number of matches accepted / suggested matches. (SMS): Average size of suggested matches.(PoD): Matched task popularity measured by average product of degrees (TH): Total number of ORpairs held. (HT): Average number of times a hanging ORpair is held. (HWT): Max wait time of a user in a held node Proposed and (to be) experimented with in [unpublished] by kabir@singularitynet.io: (Static performance): Time required by the network to find known-to-exist matches in the network which are pre-calculated in advance; (Learning rate): Time required by the network to find subsequently injected known-to-exist matches; 2.3.1 Information integration Conceptually the most interesting potential measure of performance of the network is information integration Φ, proposed by (Edelman and Tononi 2000). Φ formally defines coordinated clusters in networks of interacting agents across time and space and is used by (Tononi 2004) in developing an integrated theory of consciousness. Intuitively, “[a] subset of elements within a system will constitute an integrated process if, on a given time scale, these elements interact much more strongly among themselves than with the rest of the system” (Edelman and Tononi 2000, 135). Such measure could in principle allow to detect the emergence of ‘higher scale agents’ in the self-organizing network (see Memory / learning: emergence of identities) and goes far beyond Offer Networks as could be an overall measure of measuring intelligence – which would be fascinating to experiment with on Offer Networks in simplified manner (and SingularityNET for that matter). Measuring information integration of a dynamic network of heterogeneous agents adds another layer of complexity to the simulation, as the calculation of information integration may take considerable computational resources (potentially more than simulation itself…). While this is an interesting avenue to explore in the context of AGI research it is not currently considered in computational framework. 2.4 Goals and phases of the project 2.4.1 Goals (in no particular order) Medium-term: enable Offer Networks as an alternative to token-based exchange on SingularityNET…. Or rather, as a superclass of token-based exchange, since one type of offer that can be made is “to pay to X a certain number N of tokens of type T”; Implementation-wise / medium term: formulate offers and demands in a predicate-logic type format, compilable into executable smart contract form; Continuous: Integration with SingularityNET prototype (Python, Solidity, Ethereum, etc.); Short term: find an actual AI task to simulate for PR, communication purposes, conceptual coherence, etc – for booting a fast prototyping process (see Use Cases). Long-term: build an economic exchange network that would perform ‘better’ than purely monetary based exchanges (better in terms of global value created, customer satisfaction, etc.); Continuous: build and perform a fast prototyping / modelling / experimenting pipeline that feeds back to the conceptual development (related to 4); Short-term: design the architecture which allows to combine: rich/expensive small-scale experiments, which let us explore and understand in-depth application implementation strategies, but aren’t actually more efficient than centralized approaches at the scale on which they’re being run more simplistic scalable simulations, aimed at demonstrating/exploring the efficiency advantage achievable via decentralized methods at large scale 2.4.2 Phases (short-term): Exploratory work implementing Offer Networks atop SingularityNET and running preliminary experiments and simulations aimed at gaining knowledge and intuition. It may be beneficial to first construct experiments and simulations of isolated open problems / features to consider (search, memory, etc.) and get insights about them individually before integrating everything into one system. For this we may need to work out a more fine-grained schedule of goals / phases. (medium-term): Get a concrete sense of what sorts of AI-related exchanges are going to have the property that Offer Network type exchange works better for them than token based exchange; (long-term): Design and implement a scalable version of Offer Networks within SingularityNET, for handling an appropriate subset of AI interactions; 2.5 Practical use cases and models Possible real-world use-cases / models are: Contact list sharing; Biomedical analytics; Fintech; Cybersecurity; Internet of Things; Data exchange between microservices; Paper reviewing GitHub code contributions Offering of expertise; Decentralized chatbot; Personalized Open Eduction for the Masses; Offer Networks is a concept of an alternative economy where Agents (humans, AIs and or more/less simple programs and intelligences) find, negotiate and execute locally and globally beneficial series of not-only-monetary exchanges of goods (tangible and/or intangible). The initial motivation is to find conceptual and implementable ways for humans to express and share complex inter-subjective values of exchangeable items in fundamentally richer way than ‘flat’ &amp; ‘one-dimensional’ monetary economy warrants, while still leveraging advantages of it. Conceptually, one can generalize humans to any agents or processes, material / immaterial goods to any items (e.g. data) and by doing this come close to a general concept of ‘distributed marketplace of intelligences’ – which is SingularityNET is all about (only without strict emphasis on AI). The conceptual (and of course implementational) details of Offer Network are still very much in development (see list of resources to date in References) and both have to advance together with the SingularityNET concept and infrastructure in a ‘simulation modelling way’. The idea is that concept - development - simulations - experiments have to co- inform each other in most efficient way. References "],
["computational-framework.html", "Chapter 3 Computational Framework 3.1 Actor model of computation 3.2 Graph computing framework", " Chapter 3 Computational Framework The proposed Offer Networks simulation framework is based on (and is a special case of) the “open-ended computing” model, which combines two paradigms / computation models: Actor model of computation and Graph Computing Framework. 3.1 Actor model of computation A decentralized and distributed system from the computational perspective can be best described by Actor model (Agha 1986), which was introduced in 1973 as a “universal modular formalism for artificial intelligence” (Hewitt, Bishop, and Steiger 1973). The model defines interaction among independent processes via message passing that does not require a global observer / algorithm / manager. It aims to model intelligence “ […] in terms of a society of communicating knowledge-based problem-solving experts. In turn each of the experts can be viewed as a society that can be further decomposed in the same way until the primitive actors of the system are reached”. It models “the nature of the communication mechanisms needed for effective problem-solving by a society of experts and the conventions of discourse that make this possible” and is aimed for developing a framework for “problem-solving involving parallel versus serial processing and centralization versus decentralization of control and information storage” (Hewitt 1976). Over the years, actor model found its way into programming languages and paradigms, including, for example, functional programming. Also, there exists software frameworks and libraries dedicated to actor model (i.e. Akka, gpars, python/pulsar, etc.). These libraries allow for fast, yet scalable (across multiple machines) implementation of the actor model based logic. Actor model allows for operationalization of the ‘open-ended intelligence’ (Weinbaum (Weaver) and Veitas 2017,@weinbaum_weaver_open-ended_2018) concept which perceives intelligence as a formative process of self-organization in which agents themselves get formed – as opposed to seeing intelligent agents which competencies are defined with respect to an a priori given problem domain or goal. Open-ended intelligence concept emphasizes onto-genesis of intelligent agents (in terms of their cognitive development) rather than their specific properties. Considering requirements / open problems / features related to implementation of Offer Networks (see Offer Networks: conceptual framework), the operationalization of aspects of Open-ended intelligence concept with the Actor model for building simulation modelling experiments seems to be a sensible path towards a scalable infrastructure for alternative economy. Having said this one has to admit that Actor model (as well as the concept of Open-ended intelligence) is fairly abstract and does not define actual mechanisms of communications between actors and formation of their collectives able to solve complex tasks. The issue here is of course introducing the right set of constraints that will make the model more concrete without losing the essential characteristics which we would like to understand (see also the community discussion on the topic). For this a way to define logic of individual agent as well as communications between them is needed. ## Graph Computing Engine 3.2 Graph computing framework Graph computing is both a set of technologies and a way of thinking about the world in terms of graph data structures – entities connected via explicit or implicit links – and the processes working on them in terms of graph traversals (Rodriguez 2013). Very large graph data structures can be stored and processed on multiple machine clusters using modern open source or commercial distributed graph database technologies (e.g. Janusgraph, Neo4J, Azure Cosmos DB, Amazon Neptune, Data Stax Enterprise Graph, etc.). Graph traversal is a process of visiting (checking, updating or modifying) vertices and links of a graph based on the user defined constraints (or grammar) (M. A. Rodriguez 2008) and is equivalent to ‘semantically constrained’ spreading activation, which can be regarded a general method of how associative networks (including brain) operate. Modern graph traversal engines (e.g. Apache TikerPop, currently used in the offernet) use vertex-centric programming model (also called “think like a vertex”), which implements user defined programs from the perspective of any vertex in a graph rather than the whole data structure (McCune, Weninger, and Madey 2015). This paradigm allows for implementation of decentralized model as well as other important features discussed in the Conceptual framework. Furthermore, both the paradigm and available technologies are massively scalable – allowing to process very large data structures without requiring to store/access them at once which (not incidentally) follows the conceptual approach to the world as a decentralized system – which cannot be properly modelled by assuming a global omniscient observer (see conceptual perspective of decentralized IT governance and (M. A. Rodriguez Marko 2008)). References "],
["references.html", "References", " References "]
]
