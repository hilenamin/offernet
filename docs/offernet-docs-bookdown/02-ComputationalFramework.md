# Computational Framework

The proposed Offer Networks simulation framework is based on (and is a special case of) the “open-ended computing” model, which combines two paradigms / computation models: Actor model of computation and Graph Computing Framework. 

## Actor model of computation

A decentralized and distributed system from the computational perspective can be best described by Actor model [@agha_actors:_1986], which was introduced in 1973 as a "universal modular formalism for artificial intelligence" [@hewitt_universal_1973]. The model defines interaction among independent processes via message passing that does not require a global observer / algorithm / manager. It aims to model intelligence “ [...] in terms of a society of communicating knowledge-based problem-solving experts. In turn each of the experts can be viewed as a society that can be further decomposed in the same way until the primitive actors of the system are reached”. It models “the nature of the communication mechanisms needed for effective problem-solving by a society of experts and the conventions of discourse that make this possible” and is aimed for developing a framework for “problem-solving involving parallel versus serial processing and centralization versus decentralization of control and information storage” [@hewitt_viewing_1976]. 

Over the years, actor model found its way into programming languages and paradigms, including, for example, functional programming. Also, there exists software frameworks and libraries dedicated to actor model (i.e. [Akka](https://akka.io/), [gpars](http://www.gpars.org/webapp/home.html), [python/pulsar](https://docs.pulsarweb.org/en/latest/), etc.). These libraries allow for fast, yet scalable (across multiple machines) implementation of the actor model based logic.

Actor model allows for operationalization of the ‘open-ended intelligence’ [@weinbaum_weaver_open_2017,@weinbaum_weaver_open-ended_2018] concept which perceives intelligence as a formative process of self-organization in which agents themselves get formed  -- as opposed to seeing intelligent agents which competencies are defined with respect to an a priori given problem domain or goal. Open-ended intelligence concept emphasizes onto-genesis of intelligent agents (in terms of their cognitive development) rather than their specific properties. Considering requirements / open problems / features related to implementation of Offer Networks (see Offer Networks: conceptual framework), the operationalization of aspects of Open-ended intelligence concept with the Actor model for building simulation modelling experiments seems to be a sensible path towards a scalable infrastructure for alternative economy.

Having said this one has to admit that Actor model (as well as the concept of Open-ended intelligence) is fairly abstract and does not define actual mechanisms of communications between actors and formation of their collectives able to solve complex tasks. The issue here is of course introducing the right set of constraints that will make the model more concrete without losing the essential characteristics which we would like to understand (see also the [community discussion](https://community.singularitynet.io/t/open-ended-intelligence/259) on the topic). For this a way to define logic of individual agent as well as communications between them is needed. ## Graph Computing Engine

## Graph computing framework

Graph computing is both a set of technologies and a way of thinking about the world in terms of graph data structures -- entities connected via explicit or implicit links -- and the processes working on them in terms of graph traversals [@rodriguez_graph_2013]. Very large graph data structures can be stored and processed on multiple machine clusters using modern open source or commercial distributed graph database technologies (e.g. [Janusgraph](http://janusgraph.org/), [Neo4J](https://neo4j.com/), [Azure Cosmos DB](https://docs.microsoft.com/en-us/azure/cosmos-db/introduction), [Amazon Neptune](https://aws.amazon.com/neptune/), [Data Stax Enterprise Graph](https://www.datastax.com/products/datastax-enterprise-graph), etc.). 

*Graph traversal* is a process of visiting (checking, updating or modifying) vertices and links of a graph based on the user defined constraints (or grammar) [@rodriguez_grammar-based_2008]  and is equivalent to ‘semantically constrained' [spreading activation](https://en.wikipedia.org/wiki/Spreading_activation), which can be regarded a general method of how associative networks (including brain) operate. Modern graph traversal engines (e.g. [Apache TikerPop](http://tinkerpop.apache.org/), currently used in the [offernet](https://github.com/singnet/offernet)) use vertex-centric programming model (also called "think like a vertex"), which implements user defined programs from the perspective of any vertex in a graph rather than the whole data structure [@mccune_thinking_2015]. This paradigm allows for implementation of decentralized model as well as other important features discussed in the [Conceptual framework](../../1-ConceptualFramework/README.md). Furthermore, both the paradigm and available technologies are massively scalable -- allowing to process very large data structures without requiring to store/access them at once which (not incidentally) follows the conceptual approach to the world as a decentralized system -- which cannot be properly modelled by assuming a global omniscient observer (see conceptual perspective of [decentralized IT governance](http://freedomandconstraint.github.io/distributed-it-governance/2.html) and [@atlee_collectively_2008]).